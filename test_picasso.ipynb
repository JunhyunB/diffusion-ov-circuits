{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD Concept Control - Picasso Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "from transformers import CLIPTokenizer, CLIPTextModel\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SingularVectorInfo:\n",
    "    layer_name: str\n",
    "    head_idx: int\n",
    "    sv_idx: int\n",
    "    global_idx: int\n",
    "    contribution: float\n",
    "    singular_value: float\n",
    "\n",
    "picasso_prompt_pairs = [\n",
    "    (\"A portrait photograph\",\n",
    "     \"A cubist portrait in Pablo Picasso's geometric style\"),\n",
    "    (\"A still life photo\",\n",
    "     \"A cubist still life by Picasso\"),\n",
    "    (\"A person playing guitar\",\n",
    "     \"A guitarist painted in Picasso's cubism style\"),\n",
    "    (\"A woman portrait\",\n",
    "     \"A woman depicted in Picasso's cubist style\")\n",
    "]\n",
    "\n",
    "picasso_test_prompts = [\n",
    "    \"A cubist painting by Pablo Picasso\",\n",
    "    \"Abstract figures in Picasso's style\",\n",
    "    \"A portrait in Picasso's blue period style\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressiveSVController:\n",
    "    \n",
    "    def __init__(self, model_name: str = \"stabilityai/stable-diffusion-2-1-base\"):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.dtype = torch.float16\n",
    "        \n",
    "        print(f\"Loading model: {model_name}\")\n",
    "        self.pipe = StableDiffusionPipeline.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=self.dtype,\n",
    "            safety_checker=None,\n",
    "            requires_safety_checker=False\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.pipe.scheduler = DDIMScheduler.from_config(self.pipe.scheduler.config)\n",
    "        self.pipe.set_progress_bar_config(disable=True)\n",
    "        \n",
    "        self.unet = self.pipe.unet\n",
    "        self.text_encoder = self.pipe.text_encoder\n",
    "        self.tokenizer = self.pipe.tokenizer\n",
    "        \n",
    "        self.cross_attentions = self._collect_cross_attention_layers()\n",
    "        \n",
    "        self.total_heads = sum(module.heads for _, module in self.cross_attentions)\n",
    "        self.head_dim = 64\n",
    "        self.total_svs = self.total_heads * self.head_dim\n",
    "        \n",
    "        print(f\"Total heads: {self.total_heads}\")\n",
    "        print(f\"Total singular vectors: {self.total_svs:,}\")\n",
    "        \n",
    "        self.svd_cache = {}\n",
    "        self.hooks = []\n",
    "        self.concept_sv_cache = {}\n",
    "    \n",
    "    def _collect_cross_attention_layers(self):\n",
    "        cross_attentions = []\n",
    "        for name, module in self.unet.named_modules():\n",
    "            if name.endswith(\"attn2\") and hasattr(module, 'to_v'):\n",
    "                cross_attentions.append((name, module))\n",
    "        return cross_attentions\n",
    "    \n",
    "    def get_text_embedding(self, prompt: str) -> torch.Tensor:\n",
    "        text_inputs = self.tokenizer(\n",
    "            prompt,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.tokenizer.model_max_length,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            text_embeddings = self.text_encoder(text_inputs.input_ids.to(self.device))[0]\n",
    "        \n",
    "        return text_embeddings\n",
    "    \n",
    "    def get_svd_decomposition(self, layer_name: str, module: nn.Module, head_idx: int):\n",
    "        cache_key = f\"{layer_name}_head{head_idx}\"\n",
    "        \n",
    "        if cache_key not in self.svd_cache:\n",
    "            W_V = module.to_v.weight\n",
    "            W_O = module.to_out[0].weight\n",
    "            \n",
    "            hidden_dim = W_V.shape[0]\n",
    "            output_dim = W_O.shape[0]\n",
    "            num_heads = module.heads\n",
    "            head_dim = hidden_dim // num_heads\n",
    "            \n",
    "            # per_head analysis\n",
    "            start_idx = head_idx * head_dim\n",
    "            end_idx = (head_idx + 1) * head_dim\n",
    "\n",
    "            W_V_head = W_V[start_idx:end_idx, :]\n",
    "            W_O_head = W_O[:, start_idx:end_idx]\n",
    "            \n",
    "            W_OV = W_O_head @ W_V_head\n",
    "            \n",
    "            U, S, Vt = torch.linalg.svd(W_OV.float(), full_matrices=False)\n",
    "            \n",
    "            rank = min(U.shape[1], head_dim)\n",
    "            U = U[:, :rank]\n",
    "            S = S[:rank]\n",
    "            Vt = Vt[:rank, :]\n",
    "            \n",
    "            self.svd_cache[cache_key] = {\n",
    "                'U': U.to(self.dtype),\n",
    "                'S': S.to(self.dtype),\n",
    "                'Vt': Vt.to(self.dtype),\n",
    "                'head_dim': head_dim,\n",
    "                'output_dim': output_dim\n",
    "            }\n",
    "        \n",
    "        return self.svd_cache[cache_key]\n",
    "    \n",
    "    def analyze_sv_contributions(self, prompt_pairs: List[Tuple[str, str]], \n",
    "                                 concept_name: str = None) -> List[SingularVectorInfo]:\n",
    "        \n",
    "        if concept_name and concept_name in self.concept_sv_cache:\n",
    "            print(f\"Using cached SV analysis for '{concept_name}'\")\n",
    "            return self.concept_sv_cache[concept_name]\n",
    "        \n",
    "        print(f\"\\nAnalyzing SV contributions across {len(prompt_pairs)} prompt pairs...\")\n",
    "        \n",
    "        all_sv_infos = []\n",
    "        global_sv_idx = 0\n",
    "        \n",
    "        with tqdm(total=self.total_heads, desc=\"Analyzing heads\") as pbar:\n",
    "            for layer_name, module in self.cross_attentions:\n",
    "                for head_idx in range(module.heads):\n",
    "                    svd_data = self.get_svd_decomposition(layer_name, module, head_idx)\n",
    "                    S = svd_data['S']\n",
    "                    Vt = svd_data['Vt']\n",
    "                    \n",
    "                    sv_contributions = np.zeros(self.head_dim)\n",
    "                    \n",
    "                    for base_prompt, concept_prompt in prompt_pairs:\n",
    "                        base_emb = self.get_text_embedding(base_prompt)[0].mean(dim=0)\n",
    "                        concept_emb = self.get_text_embedding(concept_prompt)[0].mean(dim=0)\n",
    "                        \n",
    "                        for sv_idx in range(min(self.head_dim, len(S))):\n",
    "                            v_i = Vt[sv_idx, :]\n",
    "                            base_proj = (base_emb @ v_i).item()\n",
    "                            concept_proj = (concept_emb @ v_i).item()\n",
    "                            \n",
    "                            contribution = abs(S[sv_idx].item() * (concept_proj - base_proj))\n",
    "                            sv_contributions[sv_idx] += contribution\n",
    "                    \n",
    "                    sv_contributions /= len(prompt_pairs)\n",
    "                    \n",
    "                    for sv_idx in range(self.head_dim):\n",
    "                        sv_info = SingularVectorInfo(\n",
    "                            layer_name=layer_name,\n",
    "                            head_idx=head_idx,\n",
    "                            sv_idx=sv_idx,\n",
    "                            global_idx=global_sv_idx,\n",
    "                            contribution=sv_contributions[sv_idx],\n",
    "                            singular_value=S[sv_idx].item() if sv_idx < len(S) else 0.0\n",
    "                        )\n",
    "                        all_sv_infos.append(sv_info)\n",
    "                        global_sv_idx += 1\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "        \n",
    "        all_sv_infos.sort(key=lambda x: x.contribution, reverse=True)\n",
    "        \n",
    "        if concept_name:\n",
    "            self.concept_sv_cache[concept_name] = all_sv_infos\n",
    "        \n",
    "        print(f\"\\nTop 5 SV contributions:\")\n",
    "        for i, sv in enumerate(all_sv_infos[:5]):\n",
    "            layer_short = sv.layer_name.split('.')[-2]\n",
    "            print(f\"  {i+1}. {layer_short}_h{sv.head_idx}_sv{sv.sv_idx}: {sv.contribution:.6f}\")\n",
    "        \n",
    "        return all_sv_infos\n",
    "    \n",
    "    def select_top_svs(self, sv_infos: List[SingularVectorInfo], percentage: float) -> List[SingularVectorInfo]:\n",
    "        num_to_select = int(self.total_svs * percentage / 100)\n",
    "        selected = sv_infos[:num_to_select]\n",
    "        \n",
    "        print(f\"Selected {percentage}% = {num_to_select:,}/{self.total_svs:,} SVs\")\n",
    "        \n",
    "        return selected\n",
    "    \n",
    "    def create_sv_control_hooks(self, selected_svs: List[SingularVectorInfo], \n",
    "                                multiplier: float = 0.0, mode: str = 'control'):\n",
    "        self.clear_hooks()\n",
    "        \n",
    "        svs_by_layer_head = defaultdict(lambda: defaultdict(list))\n",
    "        for sv in selected_svs:\n",
    "            svs_by_layer_head[sv.layer_name][sv.head_idx].append(sv)\n",
    "        \n",
    "        print(f\"Creating {mode} mode hooks with multiplier ×{multiplier} for {len(selected_svs)} SVs\")\n",
    "        \n",
    "        for layer_name, heads_data in svs_by_layer_head.items():\n",
    "            module = None\n",
    "            for l_name, m in self.cross_attentions:\n",
    "                if l_name == layer_name:\n",
    "                    module = m\n",
    "                    break\n",
    "            \n",
    "            if module is None:\n",
    "                continue\n",
    "            \n",
    "            def create_hook(layer_name, module, heads_data, multiplier, mode):\n",
    "                def hook_fn(module, inputs, outputs):\n",
    "                    batch_size, seq_len, hidden_dim = outputs.shape\n",
    "                    \n",
    "                    if mode == 'isolate':\n",
    "                        new_outputs = torch.zeros_like(outputs)\n",
    "                        \n",
    "                        for head_idx, sv_list in heads_data.items():\n",
    "                            svd_data = self.get_svd_decomposition(layer_name, module, head_idx)\n",
    "                            U = svd_data['U']\n",
    "                            \n",
    "                            for sv_info in sv_list:\n",
    "                                if sv_info.sv_idx < U.shape[1]:\n",
    "                                    u_vec = U[:, sv_info.sv_idx].to(outputs.device)\n",
    "                                    \n",
    "                                    outputs_flat = outputs.view(-1, hidden_dim)\n",
    "                                    projection = outputs_flat @ u_vec\n",
    "                                    \n",
    "                                    reconstruction = projection.unsqueeze(1) * u_vec.unsqueeze(0)\n",
    "                                    new_outputs += reconstruction.view(batch_size, seq_len, hidden_dim)\n",
    "                        \n",
    "                        return new_outputs\n",
    "                    \n",
    "                    else:\n",
    "                        output_reshaped = outputs.reshape(batch_size * seq_len, hidden_dim)\n",
    "                        \n",
    "                        for head_idx, sv_list in heads_data.items():\n",
    "                            svd_data = self.get_svd_decomposition(layer_name, module, head_idx)\n",
    "                            U = svd_data['U']\n",
    "                            \n",
    "                            for sv_info in sv_list:\n",
    "                                if sv_info.sv_idx >= U.shape[1]:\n",
    "                                    continue\n",
    "                                \n",
    "                                u_vec = U[:, sv_info.sv_idx].to(outputs.device)\n",
    "                                \n",
    "                                projection = output_reshaped @ u_vec\n",
    "                                \n",
    "                                scale_factor = multiplier - 1.0\n",
    "                                output_reshaped += scale_factor * projection.unsqueeze(1) * u_vec.unsqueeze(0)\n",
    "                        \n",
    "                        return output_reshaped.reshape(batch_size, seq_len, hidden_dim)\n",
    "                \n",
    "                return hook_fn\n",
    "            \n",
    "            hook = create_hook(layer_name, module, heads_data, multiplier, mode)\n",
    "            handle = module.register_forward_hook(hook)\n",
    "            self.hooks.append(handle)\n",
    "    \n",
    "    def clear_hooks(self):\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "        self.hooks = []\n",
    "    \n",
    "    def generate_image(self, prompt: str, seed: int = 42, num_inference_steps: int = 30) -> Image.Image:\n",
    "        generator = torch.Generator(device=self.device).manual_seed(seed)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            image = self.pipe(\n",
    "                prompt,\n",
    "                num_inference_steps=num_inference_steps,\n",
    "                generator=generator\n",
    "            ).images[0]\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = ProgressiveSVController()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_progressive_visualization(\n",
    "    controller: ProgressiveSVController,\n",
    "    test_prompt: str,\n",
    "    sv_infos: List[SingularVectorInfo],\n",
    "    percentages: List[float] = [10, 15, 20, 25, 30, 35],\n",
    "    multiplier: float = 0.0,\n",
    "    save_path: str = None\n",
    "):\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Generating progressive visualization\")\n",
    "    print(f\"Test prompt: {test_prompt}\")\n",
    "    print(f\"Multiplier: ×{multiplier}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(\"\\nGenerating baseline...\")\n",
    "    controller.clear_hooks()\n",
    "    baseline_img = controller.generate_image(test_prompt)\n",
    "    \n",
    "    removal_images = [baseline_img]\n",
    "    isolated_images = [baseline_img]\n",
    "    \n",
    "    for pct in percentages:\n",
    "        print(f\"\\nProcessing {pct}%...\")\n",
    "        selected_svs = controller.select_top_svs(sv_infos, pct)\n",
    "        \n",
    "        controller.create_sv_control_hooks(selected_svs, multiplier=multiplier, mode='control')\n",
    "        removal_img = controller.generate_image(test_prompt)\n",
    "        removal_images.append(removal_img)\n",
    "        \n",
    "        controller.create_sv_control_hooks(selected_svs, mode='isolate')\n",
    "        iso_img = controller.generate_image(test_prompt)\n",
    "        isolated_images.append(iso_img)\n",
    "        \n",
    "        controller.clear_hooks()\n",
    "    \n",
    "    n_cols = len(percentages) + 1\n",
    "    fig_width = 3 * n_cols\n",
    "    fig_height = 6\n",
    "    \n",
    "    fig, axes = plt.subplots(2, n_cols, figsize=(fig_width, fig_height))\n",
    "    \n",
    "    col_labels = ['Original'] + [f'{p}%' for p in percentages]\n",
    "    \n",
    "    for col in range(n_cols):\n",
    "        axes[0, col].imshow(removal_images[col])\n",
    "        axes[0, col].axis('off')\n",
    "        axes[0, col].set_title(col_labels[col], fontsize=14, fontweight='bold')\n",
    "        \n",
    "        axes[1, col].imshow(isolated_images[col])\n",
    "        axes[1, col].axis('off')\n",
    "    \n",
    "    if multiplier == 0.0:\n",
    "        row1_label = 'Remove\\nconcept SVs'\n",
    "    else:\n",
    "        row1_label = f'Multiply\\nconcept SVs\\nby ×{multiplier}'\n",
    "    \n",
    "    fig.text(0.02, 0.75, row1_label, \n",
    "             fontsize=12, ha='center', va='center',\n",
    "             bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    fig.text(0.02, 0.25, 'Generate only\\nusing selected\\nSVs', \n",
    "             fontsize=12, ha='center', va='center',\n",
    "             bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgreen', alpha=0.8))\n",
    "    \n",
    "    plt.suptitle(f'{test_prompt}', fontsize=14, style='italic')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(left=0.08, top=0.92)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "        print(f\"\\nSaved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_infos = controller.analyze_sv_contributions(picasso_prompt_pairs, 'picasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt = \"A cubist painting by Pablo Picasso\"\n",
    "\n",
    "generate_progressive_visualization(\n",
    "    controller=controller,\n",
    "    test_prompt=test_prompt,\n",
    "    sv_infos=sv_infos,\n",
    "    percentages=[10, 15, 20, 25, 30],\n",
    "    multiplier=0.0, # 0.0 is for removal\n",
    "    save_path=\"picasso_removal.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt = \"Weeping woman in cubism by Pablo Picasso\"\n",
    "\n",
    "generate_progressive_visualization(\n",
    "    controller=controller,\n",
    "    test_prompt=test_prompt,\n",
    "    sv_infos=sv_infos,\n",
    "    percentages=[10, 15, 20, 25, 30],\n",
    "    multiplier=0.0,\n",
    "    save_path=\"picasso_weep.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt = \"Guernica by Pablo Picasso\"\n",
    "\n",
    "generate_progressive_visualization(\n",
    "    controller=controller,\n",
    "    test_prompt=test_prompt,\n",
    "    sv_infos=sv_infos,\n",
    "    percentages=[10, 15, 20, 25, 30],\n",
    "    multiplier=0.0,\n",
    "    save_path=\"picasso_guernica.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
